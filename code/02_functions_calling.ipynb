{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2627bbf",
   "metadata": {},
   "source": [
    "# Function Calling with GitHub Marketplace Models\n",
    "\n",
    "This notebook demonstrates how to implement and use function calling with Language Learning Models (LLMs) via GitHub Marketplace Models. Function calling allows AI models to request specific external tools or data sources when they need additional information beyond their training data.\n",
    "\n",
    "## Learning Objectives:\n",
    "\n",
    "1. Understand what function calling is and why it's important for extending LLM capabilities\n",
    "2. Compare standard chat completions with function-enhanced responses\n",
    "3. Implement the complete function calling workflow:\n",
    "   - Define function schemas that the model can use\n",
    "   - Send prompts with available tools\n",
    "   - Parse function call requests from the model\n",
    "   - Execute the requested functions with proper arguments\n",
    "   - Return results to the model for final response generation\n",
    "\n",
    "This notebook uses a weather function example to show how models can access real-time data that isn't in their training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6b2f64",
   "metadata": {},
   "source": [
    "# Function Calling \n",
    "\n",
    "The LLM models are limited to generation based on knowledge included in their training data or context information provided in the prompt (see RAG concepts). \n",
    "\n",
    "However, function calling allows the model extend it's capabilities and request to invoke function to perform specific tasks or retrieve information. \n",
    "\n",
    "This is particularly useful for tasks that require structured data or specific actions, such as retrieving information from a database or performing calculations.\n",
    "\n",
    "\n",
    "References: \n",
    "- https://platform.openai.com/docs/guides/function-calling\n",
    "- https://cookbook.openai.com/examples/how_to_call_functions_with_chat_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed9b24fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from openai import AsyncOpenAI, OpenAI\n",
    "from agents import (\n",
    "    Agent,\n",
    "    Runner,\n",
    "    OpenAIChatCompletionsModel,\n",
    "    ModelProvider,\n",
    "    Model,\n",
    "    RunConfig,\n",
    "    set_default_openai_client,\n",
    "    set_default_openai_api,\n",
    "    set_tracing_disabled,\n",
    "    function_tool,\n",
    ")\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "821371a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = AsyncOpenAI(\n",
    "    base_url=\"https://models.inference.ai.azure.com\",\n",
    "    api_key=os.environ[\"GITHUB_TOKEN\"],\n",
    ")\n",
    "\n",
    "client2 = OpenAI(\n",
    "    base_url=\"https://models.inference.ai.azure.com\",\n",
    "    api_key=os.environ[\"GITHUB_TOKEN\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "addbb6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def message(role, content):\n",
    "    return {\"role\": role, \"content\":\n",
    "            [{\n",
    "                \"type\": \"text\",\n",
    "                \"text\": content}]\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ba1ac61",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    message(\"developer\", \"you are a helpful assistant\"),\n",
    "    message(\"user\", \"How is the weather in Sydney today?\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6558064",
   "metadata": {},
   "source": [
    "## Standard Chat Completions call \n",
    "\n",
    "LLM has no context of realtime data or information not currently in its training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0f59a43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"content\": \"I'm unable to provide real-time weather updates. I recommend checking a reliable weather website or using a weather app for the most current information on Sydney's weather.\",\n",
      "  \"refusal\": null,\n",
      "  \"role\": \"assistant\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "completion = await client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=messages)\n",
    "\n",
    "\n",
    "\n",
    "print(completion.choices[0].message.to_json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73592dec",
   "metadata": {},
   "source": [
    "## Function Calling Example \n",
    "\n",
    "The flow of function calling is as follows:\n",
    "\n",
    "<img src=\"https://cdn.openai.com/API/docs/images/function-calling-diagram-steps.png\" alt=\"Function Calling\" width=\"400px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0280c8f",
   "metadata": {},
   "source": [
    "### Define the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bcfc76aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_weather_function_definition = {\n",
    "    \"type\": \"function\",\n",
    "    \"function\":{\n",
    "        \"name\": \"get_weather\",\n",
    "        \"description\": \"Get the current weather in a given city\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"location\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The name of the location to get the weather for\",\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"location\"],\n",
    "            \"additionalProperties\": False,\n",
    "\n",
    "        },\n",
    "    },\n",
    "    \"strict\": True\n",
    "}\n",
    "\n",
    "tools = [get_weather_function_definition]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7b8bc823",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weather(location):\n",
    "    # return f\"The weather in {location} is sunny with a high of 25°C.\"\n",
    "    return {\"temperature\": 25, \"condition\": \"sunny\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f680af",
   "metadata": {},
   "source": [
    "### 1. Send messasge with tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5fbeb618",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history = messages\n",
    "completion = await client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=chat_history,\n",
    "    tools=tools\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37d466b",
   "metadata": {},
   "source": [
    "### 2. Model responsds with function call "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8cdde083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"content\": null,\n",
      "  \"refusal\": null,\n",
      "  \"role\": \"assistant\",\n",
      "  \"tool_calls\": [\n",
      "    {\n",
      "      \"id\": \"call_A0GbXBeZGkAR1ooDoMKQCPcs\",\n",
      "      \"function\": {\n",
      "        \"arguments\": \"{\\\"location\\\":\\\"Sydney\\\"}\",\n",
      "        \"name\": \"get_weather\"\n",
      "      },\n",
      "      \"type\": \"function\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# print(completion.to_json())\n",
    "\n",
    "print(completion.choices[0].message.to_json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8663d650",
   "metadata": {},
   "source": [
    "must append the function call request to the message history, then perform the requested function call. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "64726090",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'developer',\n",
       "  'content': [{'type': 'text', 'text': 'you are a helpful assistant'}]},\n",
       " {'role': 'user',\n",
       "  'content': [{'type': 'text',\n",
       "    'text': 'How is the weather in Sydney today?'}]},\n",
       " {'content': None,\n",
       "  'refusal': None,\n",
       "  'role': 'assistant',\n",
       "  'tool_calls': [{'id': 'call_A0GbXBeZGkAR1ooDoMKQCPcs',\n",
       "    'function': {'arguments': '{\"location\":\"Sydney\"}', 'name': 'get_weather'},\n",
       "    'type': 'function'}]}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history.append(json.loads(completion.choices[0].message.to_json()))  # append model's function call message\n",
    "chat_history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b013de3",
   "metadata": {},
   "source": [
    "### 3. Execute Function call \n",
    "\n",
    "Inspect the finish_reson, if it is \"tool_calls\", then proceed to execute the request function with arguments specified by the LLM function call request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "79e3f0ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tool_calls\n",
      "{\n",
      "  \"id\": \"call_A0GbXBeZGkAR1ooDoMKQCPcs\",\n",
      "  \"function\": {\n",
      "    \"arguments\": \"{\\\"location\\\":\\\"Sydney\\\"}\",\n",
      "    \"name\": \"get_weather\"\n",
      "  },\n",
      "  \"type\": \"function\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "finish_reason = completion.choices[0].finish_reason\n",
    "print(finish_reason)\n",
    "tool_calls = completion.choices[0].message.tool_calls\n",
    "print(tool_calls[0].to_json())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae59bd3",
   "metadata": {},
   "source": [
    "Execute the fucntion, and append function call result to the message history. Must tool_call_id returned by the LLM function call request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6a33da26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "call_A0GbXBeZGkAR1ooDoMKQCPcs\n",
      "get_weather\n",
      "{\"location\":\"Sydney\"}\n",
      "{'temperature': 25, 'condition': 'sunny'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for tool in tool_calls:\n",
    "    print(tool.id)\n",
    "    print(tool.function.name)\n",
    "    print(tool.function.arguments)\n",
    "    function_name = tool.function.name\n",
    "    function_args = json.loads(tool.function.arguments)\n",
    "    tool_call_id = tool.id\n",
    "\n",
    "\n",
    "\n",
    "    # execute the function call and append the results as a ToolMessage in the message history\n",
    "    function_call_results = locals()[function_name](**function_args)\n",
    "    print(function_call_results)\n",
    "    function_call_results_message = {\n",
    "        \"role\": \"tool\",\n",
    "        \"type\": \"function_call_output\",\n",
    "        \"tool_call_id\": tool_call_id,\n",
    "        \"content\": str(function_call_results)\n",
    "    }\n",
    "\n",
    "\n",
    "    chat_history.append(function_call_results_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1ee142ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"{'temperature': 25, 'condition': 'sunny'}\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(function_call_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9c2d7e11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'developer',\n",
       "  'content': [{'type': 'text', 'text': 'you are a helpful assistant'}]},\n",
       " {'role': 'user',\n",
       "  'content': [{'type': 'text',\n",
       "    'text': 'How is the weather in Sydney today?'}]},\n",
       " {'content': None,\n",
       "  'refusal': None,\n",
       "  'role': 'assistant',\n",
       "  'tool_calls': [{'id': 'call_A0GbXBeZGkAR1ooDoMKQCPcs',\n",
       "    'function': {'arguments': '{\"location\":\"Sydney\"}', 'name': 'get_weather'},\n",
       "    'type': 'function'}]},\n",
       " {'role': 'tool',\n",
       "  'type': 'function_call_output',\n",
       "  'tool_call_id': 'call_A0GbXBeZGkAR1ooDoMKQCPcs',\n",
       "  'content': \"{'temperature': 25, 'condition': 'sunny'}\"}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9796b787",
   "metadata": {},
   "source": [
    "### 4. Send the result back to the model\n",
    "\n",
    "Send the result of the function call back to the model as a message. This message should include the function call result and message history. Function call result must correctly include tool_call_id, so that the model can match the result with the original function call request.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a02e0ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_2 = await client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=chat_history,\n",
    "    tools=tools\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0782bf",
   "metadata": {},
   "source": [
    "### 5. Model final response \n",
    "\n",
    "\n",
    "The model will then respond with a message that includes the result of the function call. This message can be used to continue the conversation or provide additional information to the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ca1563a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weather in Sydney today is sunny with a temperature of 25°C.\n"
     ]
    }
   ],
   "source": [
    "print(response_2.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "40b9dad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"content\": \"The weather in Sydney today is sunny with a temperature of 25°C.\",\n",
      "  \"refusal\": null,\n",
      "  \"role\": \"assistant\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(response_2.choices[0].message.to_json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b80cee",
   "metadata": {},
   "source": [
    "### 6. Continue the conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bb2a0f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"content\": \"الطقس في سيدني اليوم مشمس ودرجة الحرارة 25°C.\",\n",
      "  \"refusal\": null,\n",
      "  \"role\": \"assistant\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# always append model response to the chat history\n",
    "chat_history.append(json.loads(response_2.choices[0].message.to_json()))  # append model's function call message\n",
    "# new user message\n",
    "chat_history.append(message(\"user\", \"what again in Arabic please?\"))\n",
    "response_3 = await client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=chat_history,\n",
    "    tools=tools\n",
    ")\n",
    "\n",
    "\n",
    "print(response_3.choices[0].message.to_json())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
