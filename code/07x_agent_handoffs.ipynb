{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe52035e",
   "metadata": {},
   "source": [
    "https://github.com/openai/openai-agents-python/blob/main/examples/basic/agent_lifecycle_example.py \n",
    "\n",
    "two agents\n",
    "each has its own tools \n",
    "\n",
    "1. starter agents: will process the initial user request, will use tools as needed and will handoff to other agents if required\n",
    "2. multiply agent: knows how to perform arithmetic operations (can we configure a handoff)\n",
    "\n",
    "example also keeps tracks of agent life cycle events \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3f0c45d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from agents import (\n",
    "\n",
    "    Agent,\n",
    "    Runner,\n",
    "    RunConfig,\n",
    "    trace,\n",
    "    ModelSettings,\n",
    "    AgentHooks,\n",
    "    RunHooks,\n",
    "    TContext,\n",
    "    MaxTurnsExceeded,\n",
    "    Tool\n",
    ")\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Optional, Dict, Any\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "467e7783",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import Agent, RawResponsesStreamEvent, Runner, TResponseInputItem, trace\n",
    "from helpers.trace_util import get_trace_url\n",
    "from agents.extensions.visualization import draw_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c00e1ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.model_client import (\n",
    "    get_openai_client,\n",
    "    get_github_model_provider\n",
    ")\n",
    "\n",
    "model_name = \"gpt-4o-mini\"\n",
    "\n",
    "GITHUB_MODEL_PROVIDER = get_github_model_provider(\n",
    "    client = get_openai_client(),\n",
    "    model = model_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c1c7ae6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents.extensions.handoff_prompt import RECOMMENDED_PROMPT_PREFIX\n",
    "from agents import handoff, RunContextWrapper\n",
    "\n",
    "\n",
    "class Joke(BaseModel):\n",
    "    joke: str = Field(description=\"The joke text\")\n",
    "    punchline: str = Field(description=\"The punchline of the joke\")\n",
    "    language: str = Field(description=\"The language of the joke\")\n",
    "\n",
    "\n",
    "class Translation(BaseModel):\n",
    "    content: str = Field(description=\"Content\")\n",
    "    language: str = Field(description=\"The language of the translation\")\n",
    "\n",
    "async def on_handoff1(ctx: RunContextWrapper[None], input_data: Translation):\n",
    "    print(f\"agent {ctx} called with: {input_data.content}\")\n",
    "\n",
    "dad_jokes_agent = Agent(\n",
    "    name=\"dad_jokes_generator_agent\",\n",
    "    instructions=(\n",
    "        # f\"{RECOMMENDED_PROMPT_PREFIX} \\n\"\n",
    "        \"You are an agent that specialises in generating jokes, dad jokes specifically. \"\n",
    "        \"You only respond with dad jokes.\"\n",
    "        \"You do not answer any other questions. \"\n",
    "        \"always deliver a punchline. \"\n",
    "        \" ## IMPORTANT ##\"\n",
    "        \"Always respond in English, even if the user asks in a different language. \"\n",
    "        \"You don't end the conversation, you must handoff to another agent.\"\n",
    "    ),\n",
    "    handoff_description=(\n",
    "        \"An agent capable of generating jokes in English\"\n",
    "    ),\n",
    "    model=model_name,\n",
    "    output_type=Joke,\n",
    ")\n",
    "\n",
    "\n",
    "spanish_agent = Agent(\n",
    "    name=\"spanish_agent\",\n",
    "    instructions= \"\"\"\n",
    "        You translate the input message to Spanish.\n",
    "        You don't generate new content.\n",
    "        ## IMPORTANT ##\n",
    "        You don't end the conversation, you must handoff to another agent.\n",
    "        only handoff to a single agent at a time\n",
    "\n",
    "        \"\"\",\n",
    "    handoff_description=\"\"\"\n",
    "    You translate content to spanish.\n",
    "    \"\"\",\n",
    "    model=model_name,\n",
    "    output_type=Translation,\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "french_agent = Agent(\n",
    "    name=\"french_agent\",\n",
    "    instructions= \"\"\"\n",
    "        You translate the input message to French.\n",
    "        You don't generate new content.\n",
    "        ## IMPORTANT ##\n",
    "        You don't end the conversation, you must handoff to another agent.\n",
    "        only handoff to a single agent at a time\n",
    "\n",
    "\n",
    "        \"\"\",\n",
    "    handoff_description=\"you translate content to french\",\n",
    "    model=model_name,\n",
    "    output_type=Translation,\n",
    ")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968e336f",
   "metadata": {},
   "source": [
    "# Deterministic Workflow: Manual Orchestration\n",
    "\n",
    "In this example, we will execute a manual handoff between agents in a sequential workflow. \n",
    "\n",
    "All of the agents produce structured outputs. \n",
    "\n",
    "The output of one agent is used as the input to the next agent, after appending to it an additional handoff instruction message.\n",
    "\n",
    "Notice in the trace afterwards how the full message history is preserved, including the handoff instruction message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8d568294",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def handoff_instructions_msg(lang: str):\n",
    "    return {\"role\": \"user\", \"content\": f\"Translate the following text to {lang}\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7a8fb4b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trace URL: https://platform.openai.com/traces/trace?trace_id=trace_f3ed07096e8441ddbad5f620532431e4\n",
      "RunResult:\n",
      "- Last agent: Agent(name=\"dad_jokes_generator_agent\", ...)\n",
      "- Final output (Joke):\n",
      "    {\n",
      "      \"joke\": \"Why did the scarecrow win an award?\",\n",
      "      \"punchline\": \"Because he was outstanding in his field!\",\n",
      "      \"language\": \"English\"\n",
      "    }\n",
      "- 1 new item(s)\n",
      "- 1 raw response(s)\n",
      "- 0 input guardrail result(s)\n",
      "- 0 output guardrail result(s)\n",
      "(See `RunResult` for more details)\n",
      "First joke as Joke: joke='Why did the scarecrow win an award?' punchline='Because he was outstanding in his field!' language='English'\n",
      "Spanish translation as Joke: joke='¿Por qué el espantapájaros ganó un premio?' punchline='¡Porque era excepcional en su campo!' language='Spanish'\n",
      "French translation as Joke: joke='Pourquoi le épouvantail a-t-il gagné un prix ?' punchline=\"Parce qu'il était exceptionnel dans son domaine !\" language='French'\n",
      "joke='Pourquoi le épouvantail a-t-il gagné un prix ?' punchline=\"Parce qu'il était exceptionnel dans son domaine !\" language='French'\n"
     ]
    }
   ],
   "source": [
    "input_list = [\n",
    "    {\"role\": \"user\", \"content\": \"Tell me a dad joke\"},\n",
    "]\n",
    "\n",
    "\n",
    "with trace(\"dad_jokes_agent_manual_handoff\", group_id=\"dad_jokes\") as tr:\n",
    "\n",
    "    print(f\"Trace URL: {get_trace_url(tr)}\")\n",
    "\n",
    "    run_output = await Runner.run(\n",
    "        starting_agent= dad_jokes_agent,\n",
    "        input=input_list,\n",
    "        run_config = RunConfig(\n",
    "            model_provider=GITHUB_MODEL_PROVIDER,\n",
    "            model = model_name,\n",
    "        ),\n",
    "        )\n",
    "\n",
    "\n",
    "    print(run_output)\n",
    "\n",
    "    # joke_output : Joke = run_output.final_output\n",
    "    # print(f\"Joke: {joke_output.joke}\")\n",
    "    print(f\"First joke as Joke: {run_output.final_output_as(Joke)}\")\n",
    "\n",
    "\n",
    "    next_input = run_output.to_input_list()\n",
    "    next_input.append(handoff_instructions_msg(\"Spanish\"))\n",
    "\n",
    "    spanish_agent.output_type = Joke\n",
    "    spanish_output = await Runner.run(\n",
    "        starting_agent=spanish_agent,\n",
    "        input=next_input,\n",
    "        run_config = RunConfig(\n",
    "            model_provider=GITHUB_MODEL_PROVIDER,\n",
    "            model = model_name,\n",
    "        ),\n",
    "        )\n",
    "\n",
    "    print(f\"Spanish translation as Joke: {spanish_output.final_output_as(Joke)}\")\n",
    "\n",
    "\n",
    "    french_agent.output_type = Joke\n",
    "    french_agent_input = spanish_output.to_input_list()\n",
    "    french_agent_input.append(handoff_instructions_msg(\"French\"))\n",
    "    french_output = await Runner.run(\n",
    "        starting_agent=french_agent,\n",
    "        input=french_agent_input,\n",
    "        run_config = RunConfig(\n",
    "            model_provider=GITHUB_MODEL_PROVIDER,\n",
    "            model = model_name,\n",
    "        ),\n",
    "        )\n",
    "\n",
    "\n",
    "    print(f\"French translation as Joke: {french_output.final_output_as(Joke)}\")\n",
    "\n",
    "    french_output.to_input_list()\n",
    "\n",
    "\n",
    "print(french_output.final_output_as(Joke))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f7b7d41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ModelResponse(output=[ResponseOutputMessage(id='__fake_id__', content=[ResponseOutputText(annotations=[], text='{\"joke\":\"Pourquoi ne peux-tu pas donner un ballon à Elsa ?\",\"punchline\":\"Parce qu\\'elle va le laisser partir !\",\"language\":\"French\"}', type='output_text')], role='assistant', status='completed', type='message')], usage=Usage(requests=1, input_tokens=248, output_tokens=34, total_tokens=282), referenceable_id=None)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'role': 'user', 'content': 'Tell me a dad joke'},\n",
       " {'id': '__fake_id__',\n",
       "  'content': [{'annotations': [],\n",
       "    'text': '{\"joke\":\"Why can\\'t you give Elsa a balloon?\",\"punchline\":\"Because she will let it go!\",\"language\":\"English\"}',\n",
       "    'type': 'output_text'}],\n",
       "  'role': 'assistant',\n",
       "  'status': 'completed',\n",
       "  'type': 'message'},\n",
       " {'role': 'user', 'content': 'Translate the following text to Spanish'},\n",
       " {'id': '__fake_id__',\n",
       "  'content': [{'annotations': [],\n",
       "    'text': '{\"joke\":\"¿Por qué no puedes darle un globo a Elsa?\",\"punchline\":\"¡Porque lo dejará ir!\",\"language\":\"Spanish\"}',\n",
       "    'type': 'output_text'}],\n",
       "  'role': 'assistant',\n",
       "  'status': 'completed',\n",
       "  'type': 'message'},\n",
       " {'role': 'user', 'content': 'Translate the following text to French'},\n",
       " {'id': '__fake_id__',\n",
       "  'content': [{'annotations': [],\n",
       "    'text': '{\"joke\":\"Pourquoi ne peux-tu pas donner un ballon à Elsa ?\",\"punchline\":\"Parce qu\\'elle va le laisser partir !\",\"language\":\"French\"}',\n",
       "    'type': 'output_text'}],\n",
       "  'role': 'assistant',\n",
       "  'status': 'completed',\n",
       "  'type': 'message'}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(french_output.raw_responses)\n",
    "\n",
    "next_input = french_output.to_input_list()\n",
    "display(next_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "67538b42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage(requests=1, input_tokens=253, output_tokens=37, total_tokens=290)\n"
     ]
    }
   ],
   "source": [
    "print(french_output.raw_responses[-1].usage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b6f34f",
   "metadata": {},
   "source": [
    "# Implement Handoffs\n",
    "\n",
    "In this example, we will implement the handoffs using the SDK handoff functionality."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5bd0d0f",
   "metadata": {},
   "source": [
    "## Define the Orchestrator and Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ba403cd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: failed to execute WindowsPath('dot'), make sure the Graphviz executables are on your systems' PATH\n"
     ]
    }
   ],
   "source": [
    "\n",
    "user_response_agent = Agent(\n",
    "    name=\"user_response_agent\",\n",
    "    instructions=\"\"\"\n",
    "        You are an agent that generates a response to the user's message.\n",
    "        your response should include summary of steps taken to produce the final output\n",
    "        in bullet points.\n",
    "        present this execution summary as a list of steps taken to produce the final output.\"\n",
    "        then in the response back to the user, include the final output from each step,\n",
    "        the user query, and the very last final output\"\n",
    "    \"\"\",\n",
    "    handoff_description=\"\"\"\n",
    "    An agent capable of generating final user responses\n",
    "    Final user response is a summary of the steps taken to produce the final output.\n",
    "    \"\"\",\n",
    "    model=model_name,\n",
    "    output_type=str,\n",
    ")\n",
    "\n",
    "\n",
    "orchestrator_agent = Agent(\n",
    "    name=\"orchestrator_agent\",\n",
    "    model=model_name,\n",
    "    tool_use_behavior=\"run_llm_again\",\n",
    "    instructions=\"\"\"\n",
    "        You are an orchestrator agent.\n",
    "        You breakdown the task to multiple steps and handoff to appropriate agents.\n",
    "        You are capable of generating jokes, translating messages to Spanish and French.\n",
    "        If asked for multiple translations, handoff to multiple language agents.\n",
    "        You only speak English. Do not translate the user's message yourself.\n",
    "        Use translator only when you have content to be translated, otherwise, handoff to the next agent.\n",
    "        ## IMPORTANT ##\n",
    "        Structure the execution plan such that you first generate content, for example by using\n",
    "        the joke generator, then translate it using translation agents, and finally,\n",
    "        handoff to the user response agent.\n",
    "        Express your thoughts before executing the next step\n",
    "    \"\"\",\n",
    "    handoff_description=(\n",
    "        \"An agent that orchestrates tasks.\"\n",
    "        ),\n",
    "    # handoffs=[dad_jokes_agent,user_response_agent]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# # orchestrator_agent.handoffs = [dad_jokes_agent,user_response_agent]\n",
    "# dad_jokes_agent.handoffs = [spanish_agent, french_agent, user_response_agent]\n",
    "# spanish_agent.handoffs = [user_response_agent]\n",
    "# french_agent.handoffs = [user_response_agent]\n",
    "\n",
    "dad_jokes_agent.handoffs = []\n",
    "spanish_agent.handoffs = []\n",
    "french_agent.handoffs = []\n",
    "user_response_agent.handoffs = []\n",
    "orchestrator_agent.handoffs = []\n",
    "\n",
    "\n",
    "dad_jokes_agent.handoffs = [\n",
    "    handoff(orchestrator_agent),\n",
    "    # spanish_agent,\n",
    "    # french_agent,\n",
    "    ]\n",
    "\n",
    "# spanish_agent.handoffs = [user_response_agent]\n",
    "# french_agent.handoffs = [user_response_agent]\n",
    "\n",
    "orchestrator_agent.handoffs = [\n",
    "    dad_jokes_agent,\n",
    "    user_response_agent,\n",
    "    ]\n",
    "\n",
    "dad_jokes_agent.tools = [\n",
    "    spanish_agent.as_tool(\n",
    "        tool_name=\"translate_to_spanish\",\n",
    "        tool_description=\"Translate the input message to Spanish\",\n",
    "    ),\n",
    "    french_agent.as_tool(\n",
    "        tool_name=\"translate_to_french\",\n",
    "        tool_description=\"Translate the input message to French\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "\n",
    "# # Handoff callback that processes the escalation data\n",
    "async def process_handoff(ctx: RunContextWrapper, input_data: Any):\n",
    "    print(f\"[handoff] Handoff to {ctx.agent.name}\")\n",
    "    print(f\"[handoff] Input data: {input_data}\")\n",
    "    #    print(f\"[handoff] Joke: {input_data.joke}\")\n",
    "    #    print(f\"[handoff] Punchline: {input_data.punchline}\")\n",
    "    #    print(f\"[handoff] Language: {input_data.language}\")\n",
    "\n",
    "\n",
    "\n",
    "# dad_jokes_agent.handoffs = [\n",
    "#    handoff(\n",
    "#          agent=spanish_agent,\n",
    "#          input_type=Joke,\n",
    "#          on_handoff=process_handoff,\n",
    "#    ),\n",
    "#    handoff(\n",
    "#          agent=french_agent,\n",
    "#          input_type=Joke,\n",
    "#          on_handoff=process_handoff,\n",
    "#    ),\n",
    "#     handoff(\n",
    "#             agent=user_response_agent,\n",
    "#             input_type=Joke,\n",
    "#             on_handoff=process_handoff,\n",
    "#     ),\n",
    "# ]\n",
    "\n",
    "\n",
    "try:\n",
    "    gv = draw_graph(\n",
    "        orchestrator_agent,\n",
    "        filename=\"./viz/07_agent_handoffs_orchestrator_agent.gv\",\n",
    "\n",
    "    )\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "57151ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "orchestrator_agent.handoffs\n",
    "len(dad_jokes_agent.handoffs)\n",
    "dad_jokes_agent.handoffs[0]\n",
    "\n",
    "print(len(spanish_agent.handoffs))\n",
    "print(len(dad_jokes_agent.handoffs))\n",
    "print(len(french_agent.handoffs))\n",
    "print(len(orchestrator_agent.handoffs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8646b638",
   "metadata": {},
   "source": [
    "## Run the Handoff Workflow\n",
    "\n",
    "\n",
    "![handoff flow](./viz/07_agent_handoffs_orchestrator_agent.svg)\n",
    "\n",
    "This visualization shows the agent flow we've created, where the orchestrator agent directs requests to the appropriate specialized agents. The dad jokes generator produces jokes, which can then be handed off to language agents (Spanish or French) for translation, and finally to the user response agent to format the final response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "412fe1d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trace URL: https://platform.openai.com/traces/trace?trace_id=trace_6fdc9995fb444134bc8e726fedd05c26\n",
      "joke='¿Por qué se unió la gallina a una banda? ¡Porque tenía las baquetas!' punchline='¡Porque tenía las baquetas!' language='Spanish'\n"
     ]
    }
   ],
   "source": [
    "from agents import Agent, RawResponsesStreamEvent, Runner, TResponseInputItem, trace\n",
    "\n",
    "msg = input (\"Enter your message: \") or \"Hello, tell me a joke about chickens in spanish\"\n",
    "\n",
    "inputs: list[TResponseInputItem] = [{\"content\": msg, \"role\": \"user\"}]\n",
    "\n",
    "result = None\n",
    "# keeping a state object to track the workflow state\n",
    "agentic_workflow_state_object = {}\n",
    "try:\n",
    "    with trace(workflow_name=\"handoffs\", group_id=\"mdsi\") as tr:\n",
    "        print(f\"Trace URL: {get_trace_url(tr)}\")\n",
    "        result = await Runner.run(\n",
    "            starting_agent=orchestrator_agent,\n",
    "            input=inputs,\n",
    "            run_config=RunConfig(\n",
    "                model=model_name,\n",
    "                model_provider=GITHUB_MODEL_PROVIDER,\n",
    "                model_settings=ModelSettings(\n",
    "                    temperature=0.5,\n",
    "                    max_tokens=5000,\n",
    "                ),\n",
    "                ),\n",
    "\n",
    "            max_turns=10,\n",
    "        )\n",
    "\n",
    "        print(result.final_output)\n",
    "        # print(result.last_agent)\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "615af1f3",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "RunHooks.on_handoff() missing 3 required positional arguments: 'context', 'from_agent', and 'to_agent'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[69], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m hooks \u001b[38;5;241m=\u001b[39m RunHooks()\n\u001b[1;32m----> 2\u001b[0m \u001b[43mhooks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_handoff\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m hooks\u001b[38;5;241m.\u001b[39mon_tool_end()\n",
      "\u001b[1;31mTypeError\u001b[0m: RunHooks.on_handoff() missing 3 required positional arguments: 'context', 'from_agent', and 'to_agent'"
     ]
    }
   ],
   "source": [
    "hooks = RunHooks()\n",
    "hooks.on_handoff()\n",
    "hooks.on_tool_end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8bd6cce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunResult:\n",
      "- Last agent: Agent(name=\"dad_jokes_generator_agent\", ...)\n",
      "- Final output (Joke):\n",
      "    {\n",
      "      \"joke\": \"¿Por qué se unió la gallina a una banda? ¡Porque tenía las baquetas!\",\n",
      "      \"punchline\": \"¡Porque tenía las baquetas!\",\n",
      "      \"language\": \"Spanish\"\n",
      "    }\n",
      "- 6 new item(s)\n",
      "- 3 raw response(s)\n",
      "- 0 input guardrail result(s)\n",
      "- 0 output guardrail result(s)\n",
      "(See `RunResult` for more details)\n",
      "https://platform.openai.com/traces/trace?trace_id=trace_6fdc9995fb444134bc8e726fedd05c26\n"
     ]
    }
   ],
   "source": [
    "print(result)\n",
    "\n",
    "print(get_trace_url(tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06900f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.raw_responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28e79c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.trace_util import display_agent_execution_steps\n",
    "\n",
    "\n",
    "display_agent_execution_steps(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9b94c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracing_url = f\"https://platform.openai.com/traces/trace?trace_id={tr.trace_id}\"\n",
    "\n",
    "print(f\"Tracing URL: {tracing_url}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac50a878",
   "metadata": {},
   "source": [
    "## Visualise the Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef9a205",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents.extensions.visualization import draw_graph\n",
    "\n",
    "try:\n",
    "    draw_graph(orchestrator_agent, filename=\"viz/07_agent_handoffs.gv\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13cd1ad9",
   "metadata": {},
   "source": [
    "# another explains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2302a3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "french_agent = Agent(\n",
    "    name=\"french_agent\",\n",
    "    instructions=\"You only speak French\",\n",
    ")\n",
    "\n",
    "spanish_agent = Agent(\n",
    "    name=\"spanish_agent\",\n",
    "    instructions=\"You only speak Spanish\",\n",
    ")\n",
    "\n",
    "english_agent = Agent(\n",
    "    name=\"english_agent\",\n",
    "    instructions=\"You only speak English\",\n",
    ")\n",
    "\n",
    "triage_agent = Agent(\n",
    "    name=\"triage_agent\",\n",
    "    instructions=\"Handoff to the appropriate agent based on the language of the request.\",\n",
    "    handoffs=[french_agent, spanish_agent, english_agent],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa0dc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai.types.responses import ResponseContentPartDoneEvent, ResponseTextDeltaEvent\n",
    "\n",
    "from agents import Agent, RawResponsesStreamEvent, Runner, TResponseInputItem, trace\n",
    "import uuid\n",
    "\n",
    "conversation_id = str(uuid.uuid4().hex[:16])\n",
    "\n",
    "msg = input(\"Hi! We speak French, Spanish and English. How can I help? \")\n",
    "agent = triage_agent\n",
    "inputs: list[TResponseInputItem] = []\n",
    "inputs.append({\"content\": msg, \"role\": \"user\"})\n",
    "\n",
    "while True:\n",
    "    # Each conversation turn is a single trace. Normally, each input from the user would be an\n",
    "    # API request to your app, and you can wrap the request in a trace()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    with trace(\"Routing example\", group_id=conversation_id):\n",
    "        result = Runner.run_streamed(\n",
    "            agent,\n",
    "            input=inputs,\n",
    "            run_config=RunConfig(model=model_name, model_provider=GITHUB_MODEL_PROVIDER),\n",
    "        )\n",
    "        async for event in result.stream_events():\n",
    "            if not isinstance(event, RawResponsesStreamEvent):\n",
    "                continue\n",
    "            data = event.data\n",
    "            if isinstance(data, ResponseTextDeltaEvent):\n",
    "                print(data.delta, end=\"\", flush=True)\n",
    "            elif isinstance(data, ResponseContentPartDoneEvent):\n",
    "                print(\"\\n\")\n",
    "\n",
    "    inputs = result.to_input_list()\n",
    "    print(\"\\n\")\n",
    "\n",
    "\n",
    "    agent = result.current_agent\n",
    "    user_msg = input(\"Enter a message: \")\n",
    "    if user_msg in (\"exit\", \"quit\", \"\"):\n",
    "        break\n",
    "    inputs.append({\"content\": user_msg, \"role\": \"user\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29104308",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "try:\n",
    "    draw_graph(orchestrator_agent, filename=\"viz/07_agent_handoffs.gv\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
